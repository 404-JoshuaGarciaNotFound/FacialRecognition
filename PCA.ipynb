{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "#matrix operations- matlab is better for matrix, but this helps python\n",
    "import scipy.io as sio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import repmat\n",
    "#contains some operations done in matlab\n",
    "from sklearn.preprocessing import normalize\n",
    "#huge library for ML- use normalize- convert vector to unit vector\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from Cogs 118B HW 4\n",
    "\n",
    "def eigsort(V, eigvals):\n",
    "# Sort the eigenvalues from largest to smallest. Store the sorted # eigenvalues in the column vector lambd.\n",
    "    lohival = np.sort(eigvals)\n",
    "    lohiindex = np.argsort(eigvals)\n",
    "    lambd = np.flip(lohival)\n",
    "    index = np.flip(lohiindex)\n",
    "    Dsort = np.diag(lambd)\n",
    "    # Sort eigenvectors to correspond to the ordered eigenvalues. Store sorted\n",
    "\n",
    "    # eigenvectors as columns of the matrix vsort.\n",
    "    M = np.size(lambd) \n",
    "    Vsort = np.zeros((M, M)) \n",
    "    for i in range(M):\n",
    "        Vsort[:,i] = V[:,index[i]] \n",
    "    return Vsort, Dsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is from Cogs 118B HW 4\n",
    "\n",
    "def normc(Mat):\n",
    "    return normalize(Mat, norm='l2', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewvector(columnvector):\n",
    "    #This transforms the numeric vector(62500,0) of the image back into a 250 by 250 image\n",
    "    \n",
    "    plt.imshow(columnvector.reshape([250, 250], order='C'), cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(newDir):\n",
    "    \n",
    "    photosDirectory_1 = np.array(newDir)\n",
    "    \n",
    "    \n",
    "    number_of_photos = 10\n",
    "    #we want to iterate through all the photos\n",
    "    faces = []\n",
    "    #as we iterate, we will want to append the outcomes\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(number_of_photos):\n",
    "    \n",
    "        #for photo in photo directory\n",
    "        #get the numeric interpretation\n",
    "        #turn that into an array\n",
    "        #Reshape the 250 pixels by 250 pixels into a vector\n",
    "        #append the vector to the faces list\n",
    "        \n",
    "    \n",
    "        \n",
    "        photo_numbers = cv2.imread(photosDirectory_1[i], 0)\n",
    "        photo_array = np.array(photo_numbers)\n",
    "        photo_array_reshaped = photo_array.reshape([62500, ])\n",
    "    \n",
    "        faces.append(photo_array_reshaped)\n",
    "    \n",
    "    #turn the faces list into an array\n",
    "    #transpose the array\n",
    "    faces = np.array(faces)\n",
    "    faces = faces.T\n",
    "    \n",
    "    \n",
    "    \n",
    "    meanface = np.mean(faces, axis = 1)\n",
    "    #sum along column direction, so axis = 1 (this is because each column is a unique image)\n",
    "    #this is the same as (sum(faces, axis = 1)/ 48)\n",
    "    meanface = meanface[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    \n",
    "    A = faces - np.matlib.repmat(meanface, 1, 10)\n",
    "    \n",
    "    eigvals, Vold = np.linalg.eig(A.T.dot(A))\n",
    "    V, D = eigsort(Vold, eigvals)\n",
    "    \n",
    "    U = A.dot(V)\n",
    "    U = normc(U)\n",
    "    c = U.T.dot(A)\n",
    "    \n",
    "    return meanface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CelebList = []\n",
    "#This will give you all of the names in each folder\n",
    "def ReadDirect(path):\n",
    "    directory = path\n",
    "    for file2 in os.listdir(directory):\n",
    "        \n",
    "        #this is the directory of each celebrity\n",
    "        path2 = directory + file2\n",
    "        CelebList.append(path2)\n",
    "        print(path2)\n",
    "\n",
    "        #print(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Creed Bratton\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Pam Beesly\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Erin Hannon\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Jim Halpert\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Michael Scott\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Andy Bernard\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Kelly Kapoor\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Darryl Philbin\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Angela Martin\n",
      "DatasetsToTest/TheOfficeDataset/Characters/Dwight Schrute\n"
     ]
    }
   ],
   "source": [
    "path = 'DatasetsToTest/TheOfficeDataset/Characters/'\n",
    "ReadDirect(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we make a function that finds the faces of each picture\n",
    "FaceDat = cv2.CascadeClassifier(\"TrainingData/haarcascade_frontalface_default.xml\")\n",
    "EyeDat = cv2.CascadeClassifier(\"TrainingData/haarcascade_eye.xml\")\n",
    "def faceDetect(path, newDir):\n",
    "    Photo = cv2.imread(path)\n",
    "    \n",
    "    #Blur to remove extra noise\n",
    "    Photo2 = cv2.medianBlur(Photo, 3) \n",
    "    grysc = cv2.cvtColor(Photo2, cv2.COLOR_BGR2GRAY)\n",
    "    faceDetected = FaceDat.detectMultiScale(grysc, 1.1, 4)\n",
    "    eyeDetected = EyeDat.detectMultiScale(grysc, 1.3, 4)\n",
    "    #This area ensures only one face is found per image\n",
    "    facialPadding = 20\n",
    "    #The way the algorithm works is it puts faces its less confident in first and most confident last so if multiple pictures are found we just pick the last one.\n",
    "    #Should work most of the time\n",
    "    faceFound = False\n",
    "    if(len(faceDetected) != 1):\n",
    "        \n",
    "        #Gets eye coordinate\n",
    "        count = 0\n",
    "        eye1xCord = 0\n",
    "        eye1ycord = 0\n",
    "        eye2xCord = 0\n",
    "        eye2ycord = 0\n",
    "        for(ex, ey, ew, eh) in eyeDetected:\n",
    "            #Ensures only two eyes are added to the image\n",
    "            if(count < 2):\n",
    "                #cv2.rectangle(Photo, ((ex), (ey)),((ex+ew), (ey+eh)), (0, 0, 255), 2)\n",
    "                cv2.imwrite(newDir, Photo, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                if(count == 0):\n",
    "                    eye1xCord = ex\n",
    "                    eye1ycord = ey\n",
    "                if(count == 1):\n",
    "                    eye2xCord = ex\n",
    "                    eye2ycord = ey\n",
    "                count = count + 1\n",
    "        \n",
    "        numFaces = len(faceDetected)\n",
    "        \n",
    "        for i in range(numFaces):\n",
    "            x1, y1, w1, h1 = faceDetected[i]\n",
    "            xrang = x1 + w1\n",
    "            yrang = y1 + h1\n",
    "            if(eye1xCord, eye2xCord != 0):\n",
    "                eye1Exist = True\n",
    "            if(eye2xCord, eye2ycord != 0):\n",
    "                eye2Exist = True\n",
    "            #if eyes arent found then we shouldn't put the face because it could lead to errors in our mean faces.\n",
    "            if(eye1Exist, eye2Exist == True):\n",
    "                if(faceFound == False):\n",
    "                    if(eye1xCord > x1):\n",
    "                        if(eye1xCord < xrang):  \n",
    "                            if(eye1ycord > y1):\n",
    "                                if(eye1ycord < yrang):\n",
    "                                    faceFound = True\n",
    "                                    #For our paper we can use these rectangles to visualize what we are doing\n",
    "                                    #cv2.rectangle(Photo, ((x1 - facialPadding), (y1 - facialPadding)),((x1+w1+facialPadding), (y1+h1+facialPadding)), (134, 255, 20), 2)\n",
    "                                    faceModified = Photo[y1-facialPadding:y1 +facialPadding+h1, x1-facialPadding:x1+facialPadding+w1]\n",
    "                                    photo = cv2.resize(faceModified, (250, 250))\n",
    "                                    cv2.imwrite(newDir, photo, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "\n",
    "    else:\n",
    "        (x, y, w, h) = faceDetected[0]\n",
    "        faceFound = True\n",
    "        faceModified = Photo[y-facialPadding:y+facialPadding+h,x-facialPadding:x+facialPadding+w]\n",
    "        photo1 = cv2.resize(faceModified, (250, 250))\n",
    "        cv2.imwrite(newDir, photo1, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "        \n",
    "    if(faceFound == False):\n",
    "        #Delete faces that couldn't be centered\n",
    "        try:\n",
    "            os.remove(newDir)\n",
    "        except:\n",
    "            alreadyRemoved = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/median_blur.dispatch.cpp:283: error: (-215:Assertion failed) !_src0.empty() in function 'medianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f99a83533aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnewDir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(newDir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfaceDetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphotos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-41107194afa4>\u001b[0m in \u001b[0;36mfaceDetect\u001b[0;34m(path, newDir)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#Blur to remove extra noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mPhoto2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPhoto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgrysc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPhoto2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfaceDetected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFaceDat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrysc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4-dev) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/median_blur.dispatch.cpp:283: error: (-215:Assertion failed) !_src0.empty() in function 'medianBlur'\n"
     ]
    }
   ],
   "source": [
    "newDir = []\n",
    "for photos in CelebList:\n",
    "    temp = photos.replace(path, \"Output/\")\n",
    "    newDir.append(temp)\n",
    "    #print(newDir)\n",
    "    faceDetect(photos, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "#First remove empty directories\n",
    "for Directory in newDir:\n",
    "    fileExist = exists(Directory)\n",
    "    if(fileExist == False):\n",
    "        newDir.remove(Directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calcDis(a,b):\n",
    "    xfirst = a[0]\n",
    "    yfirst = a[1]\n",
    "    \n",
    "    xsecond = b[0]\n",
    "    ysecond = b[1]\n",
    "    return math.sqrt(((xsecond-xfirst)* (xsecond - xfirst)) + ((ysecond-yfirst) * (ysecond - yfirst)))\n",
    "\n",
    "def FaceAllignRotate(PhotoDirectory):\n",
    "    #Now we have to allign each face based on the angle of their eyes\n",
    "    #for PhotoDirectory in Dir:\n",
    "    try:\n",
    "        EyeDat = cv2.CascadeClassifier(\"TrainingData/haarcascade_eye.xml\")\n",
    "        PhotoToAllign = cv2.imread(PhotoDirectory)\n",
    "        PhotoToAllign = cv2.medianBlur(PhotoToAllign, 5)  \n",
    "        gryscale = cv2.cvtColor(PhotoToAllign, cv2.COLOR_BGR2GRAY)\n",
    "        eyesLoc = EyeDat.detectMultiScale(gryscale, 1.4, 4)\n",
    "        loc = 0\n",
    "        for(eyeXcord, eyeYcord, eyeWcord, eyeHcord) in eyesLoc:\n",
    "            if(loc == 0):\n",
    "                eye1 = (eyeXcord, eyeYcord, eyeWcord, eyeHcord)\n",
    "            else:\n",
    "                eye2 = (eyeXcord, eyeYcord, eyeWcord, eyeHcord)\n",
    "            cv2.rectangle(PhotoToAllign, (eyeXcord, eyeYcord), (eyeXcord+eyeWcord, eyeYcord+eyeHcord),(0, 0, 255), 2)\n",
    "            loc = loc + 1\n",
    "    \n",
    "        #Now we determine which eye corresponds with which side of the face\n",
    "        if eye1[0] < eye2[0]:\n",
    "            leftEye = eye1\n",
    "            rightEye = eye2\n",
    "        else:\n",
    "            leftEye = eye2\n",
    "            rightEye = eye1\n",
    "        #Now we calculate the coordiantes of the eye\n",
    "        leftEyeIris = (int(leftEye[0] + (leftEye[2]/2)), int(leftEye[1] + (leftEye[3]/2)))\n",
    "        lefteyeXcord = leftEyeIris[0]\n",
    "        lefteyeYcord = leftEyeIris[1]\n",
    "        \n",
    "        RightEyeIris = (int(rightEye[0] + (rightEye[2]/2)),int(rightEye[1] + (rightEye[3]/2)))\n",
    "        righteyeXcord = RightEyeIris[0]\n",
    "        righteyeYcord = RightEyeIris[1]\n",
    "        cv2.circle(PhotoToAllign, leftEyeIris, 2, (0, 255, 0), 2)\n",
    "        cv2.circle(PhotoToAllign, RightEyeIris, 2, (0, 255, 0), 2)\n",
    "        cv2.line(PhotoToAllign, RightEyeIris, leftEyeIris, (255, 0, 0), 2)\n",
    "        \n",
    "        if leftEyeIris < RightEyeIris:\n",
    "            point = (righteyeXcord, lefteyeYcord)\n",
    "            direction = -1\n",
    "        else:\n",
    "            point = (lefteyeXcord, righteyeYcord)\n",
    "            direction = 1\n",
    "        cv2.circle(PhotoToAllign, point, 2, (255, 0, 0), 2)\n",
    "        cv2.line(PhotoToAllign, RightEyeIris, leftEyeIris, (67, 67, 67), 2)\n",
    "        cv2.line(PhotoToAllign, leftEyeIris, point, (67, 67, 67), 2)\n",
    "        cv2.line(PhotoToAllign, RightEyeIris, point, (67, 67, 67), 2)\n",
    "\n",
    "        firstCord = calcDis(leftEyeIris, point)\n",
    "        secondCord = calcDis(RightEyeIris, leftEyeIris)\n",
    "        thirdCord = calcDis(RightEyeIris, point)\n",
    "    \n",
    "        cos = (secondCord*secondCord + thirdCord*thirdCord - firstCord*firstCord) / (2*secondCord*thirdCord)\n",
    "        #cos = cos\n",
    "        \n",
    "        angle = np.arccos(cos)\n",
    "        angle = (angle * 180)\n",
    "        angle = angle / math.pi\n",
    "        \n",
    "        if(direction == -1):\n",
    "            angle = 90-angle\n",
    "        #Now we generate the new image based on the angle\n",
    "\n",
    "        imageToRototae = Image.open(PhotoDirectory)\n",
    "        rotation = angle*direction\n",
    "        #Prevents rotations that are too extreme\n",
    "        if(rotation < 20):\n",
    "            if(rotation > -20):\n",
    "                rotated = imageToRototae.rotate(rotation)\n",
    "                rotated.save(PhotoDirectory)\n",
    "    except:\n",
    "        donothing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for direct in newDir:\n",
    "    FaceAllignRotate(direct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will get all of the pictures for each person\n",
    "def getPerson(path2):    \n",
    "    SolutionList = []\n",
    "    for FilepathPhotos in os.listdir(path2):\n",
    "        #print(FilepathPhotos)\n",
    "        sol = path2 + '/' + FilepathPhotos\n",
    "        SolutionList.append(sol)\n",
    "    print(SolutionList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_8.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_9.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_10.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_7.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_6.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_4.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_5.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_1.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_2.jpg', 'DatasetsToTest/TheOfficeDataset/Characters/Jan Levinson/JanLevinson_3.jpg']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ff7130a7a646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpersonDirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPerson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCelebList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmeanface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersonDirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmeanfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-035985d139f5>\u001b[0m in \u001b[0;36mPCA\u001b[0;34m(newDir)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mphoto_numbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphotosDirectory_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mphoto_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mphoto_array_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphoto_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m62500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "meanfaces = []\n",
    "num_iterations = len(CelebList)\n",
    "for i in range (num_iterations):\n",
    "    personDirectory = getPerson(CelebList[i])\n",
    "    meanface = PCA(personDirectory)\n",
    "    meanfaces.append(meanface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "409fd63ae0ed843f46d52ddbf6d5110d5f4156ce680b24ebaeed7f1f43c8d2b4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
