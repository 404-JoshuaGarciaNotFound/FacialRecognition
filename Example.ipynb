{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we read from the solution of our dataset with what our facial recognition program should output\n",
    "import os\n",
    "\n",
    "CelebList = []\n",
    "#This will give you all of the names in each folder\n",
    "def ReadDirect(path):\n",
    "    directory = path\n",
    "    for file2 in os.listdir(directory):\n",
    "        #this is the directory of each celebrity\n",
    "        path2 = directory + file2\n",
    "        CelebList.append(path2)\n",
    "        print(path2)\n",
    "        #print(file2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This directory is specific to Adam Sandler\n",
    "# To Do:\n",
    "## create a loop to iterate over each celebraities name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmallerDataSet(cleaned)/Adam_Sandler/Adam_Sandler_0001.jpg\n",
      "SmallerDataSet(cleaned)/Adam_Sandler/Adam_Sandler_0003.jpg\n",
      "SmallerDataSet(cleaned)/Adam_Sandler/Adam_Sandler_0002.jpg\n",
      "SmallerDataSet(cleaned)/Adam_Sandler/Adam_Sandler_0004.jpg\n"
     ]
    }
   ],
   "source": [
    "#path = 'DatasetsToTest/TheOfficeDataset/Characters/'\n",
    "#ReadDirect(path)\n",
    "path = 'SmallerDataSet(cleaned)/Adam_Sandler/'\n",
    "ReadDirect(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will get all of the pictures for each person\n",
    "def getPerson(path2):\n",
    "    for FilepathPhotos in os.listdir(path2):\n",
    "        print(FilepathPhotos)\n",
    "        #sol = file2 + '/' + FilepathPhotos\n",
    "        #SolutionList.append(sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for b in CelebList:\n",
    "#    getPerson(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to write a file for each specific person you would do this\n",
    "#import cv2\n",
    "\n",
    "#writeToFolder = path\n",
    "# the name of pca should probably be uniform so\n",
    "#celebName_PCA\n",
    "\n",
    "# save image\n",
    "#cv2.imwrite('writeToFolder', celebName_PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we make a function that finds the faces of each picture\n",
    "FaceDat = cv2.CascadeClassifier(\"TrainingData/haarcascade_frontalface_default.xml\")\n",
    "EyeDat = cv2.CascadeClassifier(\"TrainingData/haarcascade_eye.xml\")\n",
    "def faceDetect(path, newDir):\n",
    "    Photo = cv2.imread(path)\n",
    "    \n",
    "    #Blur to remove extra noise\n",
    "    Photo2 = cv2.medianBlur(Photo, 3) \n",
    "    grysc = cv2.cvtColor(Photo2, cv2.COLOR_BGR2GRAY)\n",
    "    faceDetected = FaceDat.detectMultiScale(grysc, 1.1, 4)\n",
    "    eyeDetected = EyeDat.detectMultiScale(grysc, 1.3, 4)\n",
    "    #This area ensures only one face is found per image\n",
    "    facialPadding = 20\n",
    "    #The way the algorithm works is it puts faces its less confident in first and most confident last so if multiple pictures are found we just pick the last one.\n",
    "    #Should work most of the time\n",
    "    faceFound = False\n",
    "    if(len(faceDetected) != 1):\n",
    "        \n",
    "        #Gets eye coordinate\n",
    "        count = 0\n",
    "        eye1xCord = 0\n",
    "        eye1ycord = 0\n",
    "        eye2xCord = 0\n",
    "        eye2ycord = 0\n",
    "        for(ex, ey, ew, eh) in eyeDetected:\n",
    "            #Ensures only two eyes are added to the image\n",
    "            if(count < 2):\n",
    "                #cv2.rectangle(Photo, ((ex), (ey)),((ex+ew), (ey+eh)), (0, 0, 255), 2)\n",
    "                cv2.imwrite(newDir, Photo, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                if(count == 0):\n",
    "                    eye1xCord = ex\n",
    "                    eye1ycord = ey\n",
    "                if(count == 1):\n",
    "                    eye2xCord = ex\n",
    "                    eye2ycord = ey\n",
    "                count = count + 1\n",
    "        \n",
    "        numFaces = len(faceDetected)\n",
    "        \n",
    "        for i in range(numFaces):\n",
    "            x1, y1, w1, h1 = faceDetected[i]\n",
    "            xrang = x1 + w1\n",
    "            yrang = y1 + h1\n",
    "            if(eye1xCord, eye2xCord != 0):\n",
    "                eye1Exist = True\n",
    "            if(eye2xCord, eye2ycord != 0):\n",
    "                eye2Exist = True\n",
    "            #if eyes arent found then we shouldn't put the face because it could lead to errors in our mean faces.\n",
    "            if(eye1Exist, eye2Exist == True):\n",
    "                if(faceFound == False):\n",
    "                    if(eye1xCord > x1):\n",
    "                        if(eye1xCord < xrang):  \n",
    "                            if(eye1ycord > y1):\n",
    "                                if(eye1ycord < yrang):\n",
    "                                    faceFound = True\n",
    "                                    #For our paper we can use these rectangles to visualize what we are doing\n",
    "                                    #cv2.rectangle(Photo, ((x1 - facialPadding), (y1 - facialPadding)),((x1+w1+facialPadding), (y1+h1+facialPadding)), (134, 255, 20), 2)\n",
    "                                    faceModified = Photo[y1-facialPadding:y1 +facialPadding+h1, x1-facialPadding:x1+facialPadding+w1]\n",
    "                                    photo = cv2.resize(faceModified, (250, 250))\n",
    "                                    cv2.imwrite(newDir, photo, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "\n",
    "    else:\n",
    "        (x, y, w, h) = faceDetected[0]\n",
    "        faceFound = True\n",
    "        faceModified = Photo[y-facialPadding:y+facialPadding+h,x-facialPadding:x+facialPadding+w]\n",
    "        photo1 = cv2.resize(faceModified, (250, 250))\n",
    "        cv2.imwrite(newDir, photo1, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "        \n",
    "    if(faceFound == False):\n",
    "        #Delete faces that couldn't be centered\n",
    "        try:\n",
    "            os.remove(newDir)\n",
    "        except:\n",
    "            alreadyRemoved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This recursively draws a rectangle around all of the faces we are reading.\n",
    "newDir = []\n",
    "for photos in CelebList:\n",
    "    temp = photos.replace(path, \"Output/\")\n",
    "    newDir.append(temp)\n",
    "    #print(newDir)\n",
    "    faceDetect(photos, temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Output/Adam_Sandler_0001.jpg',\n",
       " 'Output/Adam_Sandler_0003.jpg',\n",
       " 'Output/Adam_Sandler_0002.jpg',\n",
       " 'Output/Adam_Sandler_0004.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FaceAllignRotate(PhotoDirectory):\n",
    "    #Now we have to allign each face based on the angle of their eyes\n",
    "    #for PhotoDirectory in Dir:\n",
    "    try:\n",
    "        EyeDat = cv2.CascadeClassifier(\"TrainingData/haarcascade_eye.xml\")\n",
    "        PhotoToAllign = cv2.imread(PhotoDirectory)\n",
    "        PhotoToAllign = cv2.medianBlur(PhotoToAllign, 5)  \n",
    "        gryscale = cv2.cvtColor(PhotoToAllign, cv2.COLOR_BGR2GRAY)\n",
    "        eyesLoc = EyeDat.detectMultiScale(gryscale, 1.4, 4)\n",
    "        loc = 0\n",
    "        for(eyeXcord, eyeYcord, eyeWcord, eyeHcord) in eyesLoc:\n",
    "            if(loc == 0):\n",
    "                eye1 = (eyeXcord, eyeYcord, eyeWcord, eyeHcord)\n",
    "            else:\n",
    "                eye2 = (eyeXcord, eyeYcord, eyeWcord, eyeHcord)\n",
    "            cv2.rectangle(PhotoToAllign, (eyeXcord, eyeYcord), (eyeXcord+eyeWcord, eyeYcord+eyeHcord),(0, 0, 255), 2)\n",
    "            loc = loc + 1\n",
    "    \n",
    "        #Now we determine which eye corresponds with which side of the face\n",
    "        if eye1[0] < eye2[0]:\n",
    "            leftEye = eye1\n",
    "            rightEye = eye2\n",
    "        else:\n",
    "            leftEye = eye2\n",
    "            rightEye = eye1\n",
    "        #Now we calculate the coordiantes of the eye\n",
    "        leftEyeIris = (int(leftEye[0] + (leftEye[2]/2)), int(leftEye[1] + (leftEye[3]/2)))\n",
    "        lefteyeXcord = leftEyeIris[0]\n",
    "        lefteyeYcord = leftEyeIris[1]\n",
    "        \n",
    "        RightEyeIris = (int(rightEye[0] + (rightEye[2]/2)),int(rightEye[1] + (rightEye[3]/2)))\n",
    "        righteyeXcord = RightEyeIris[0]\n",
    "        righteyeYcord = RightEyeIris[1]\n",
    "        cv2.circle(PhotoToAllign, leftEyeIris, 2, (0, 255, 0), 2)\n",
    "        cv2.circle(PhotoToAllign, RightEyeIris, 2, (0, 255, 0), 2)\n",
    "        cv2.line(PhotoToAllign, RightEyeIris, leftEyeIris, (255, 0, 0), 2)\n",
    "        \n",
    "        if leftEyeIris < RightEyeIris:\n",
    "            point = (righteyeXcord, lefteyeYcord)\n",
    "            direction = -1\n",
    "        else:\n",
    "            point = (lefteyeXcord, righteyeYcord)\n",
    "            direction = 1\n",
    "        cv2.circle(PhotoToAllign, point, 2, (255, 0, 0), 2)\n",
    "        cv2.line(PhotoToAllign, RightEyeIris, leftEyeIris, (67, 67, 67), 2)\n",
    "        cv2.line(PhotoToAllign, leftEyeIris, point, (67, 67, 67), 2)\n",
    "        cv2.line(PhotoToAllign, RightEyeIris, point, (67, 67, 67), 2)\n",
    "\n",
    "        firstCord = calcDis(leftEyeIris, point)\n",
    "        secondCord = calcDis(RightEyeIris, leftEyeIris)\n",
    "        thirdCord = calcDis(RightEyeIris, point)\n",
    "    \n",
    "        cos = (secondCord*secondCord + thirdCord*thirdCord - firstCord*firstCord) / (2*secondCord*thirdCord)\n",
    "        #cos = cos\n",
    "        \n",
    "        angle = np.arccos(cos)\n",
    "        angle = (angle * 180)\n",
    "        angle = angle / math.pi\n",
    "        \n",
    "        if(direction == -1):\n",
    "            angle = 90-angle\n",
    "        #Now we generate the new image based on the angle\n",
    "\n",
    "        imageToRototae = Image.open(PhotoDirectory)\n",
    "        rotation = angle*direction\n",
    "        #Prevents rotations that are too extreme\n",
    "        if(rotation < 20):\n",
    "            if(rotation > -20):\n",
    "                rotated = imageToRototae.rotate(rotation)\n",
    "                rotated.save(PhotoDirectory)\n",
    "    except:\n",
    "        donothing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for direct in newDir:\n",
    "    FaceAllignRotate(direct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning the directory into an array to see shape\n",
    "\n",
    "photosDirectory_1 = np.array(newDir)\n",
    "\n",
    "#This is the numpy array of the directory of the path to the images\n",
    "#There are 247 images\n",
    "photosDirectory_1.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewvector(columnvector):\n",
    "    #This transforms the numeric vector(62500,0) of the image back into a 250 by 250 image\n",
    "    \n",
    "    plt.imshow(columnvector.reshape([250, 250], order='C'), cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-824459f1a8af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mviewvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphotosDirectory_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-cda326ead2ca>\u001b[0m in \u001b[0;36mviewvector\u001b[0;34m(columnvector)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#This transforms the numeric vector(62500,0) of the image back into a 250 by 250 image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumnvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "viewvector(cv2.imread(photosDirectory_1[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn this into a function later\n",
    "#def photos_to_array (Directory_path_list): \n",
    "\n",
    "\n",
    "\n",
    "number_of_photos = len(newDir)\n",
    "    #we want to iterate through all the photos\n",
    "faces = []\n",
    "    #as we iterate, we will want to append the outcomes\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "for i in range(number_of_photos):\n",
    "    \n",
    "    #for photo in photo directory\n",
    "        #get the numeric interpretation\n",
    "        #turn that into an array\n",
    "        #Reshape the 250 pixels by 250 pixels into a vector\n",
    "        #append the vector to the faces list\n",
    "        \n",
    "    \n",
    "    photo_dir_i =  photosDirectory_1[i]   \n",
    "    photo_numbers = cv2.imread(photo_dir_i, 0)\n",
    "    photo_array = np.array(photo_numbers)\n",
    "    photo_array_reshaped = photo_array.reshape([62500, ])\n",
    "    \n",
    "    faces.append(photo_array_reshaped)\n",
    "    \n",
    "#turn the faces list into an array\n",
    "#transpose the array\n",
    "faces = np.array(faces)\n",
    "faces = faces.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#matrix operations- matlab is better for matrix, but this helps python\n",
    "import scipy.io as sio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import repmat\n",
    "#contains some operations done in matlab\n",
    "from sklearn.preprocessing import normalize\n",
    "#huge library for ML- use normalize- convert vector to unit vector\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanface = np.mean(faces, axis = 1)\n",
    "    #sum along column direction, so axis = 1 (this is because each column is a unique image)\n",
    "    #this is the same as (sum(faces, axis = 1)/ 48)\n",
    "meanface = meanface[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewvector(meanface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "409fd63ae0ed843f46d52ddbf6d5110d5f4156ce680b24ebaeed7f1f43c8d2b4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
